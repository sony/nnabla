{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parallel Distributed Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataParallelCommunicator enables to train your neural network using \n",
    "multiple devices. It is normally used for gradients exchange in data \n",
    "parallel distributed training. Basically, there are two types of distributed trainings in Neural Network\n",
    "literature: Data Parallel and Model Parallel. Here we only focus on \n",
    "the former, Data Parallel Training. Data Parallel Distributed Training are based on the very simple equation\n",
    "in the optimization for a neural network called (Mini-Batch) Stochastic \n",
    "Gradient Descent. \n",
    "\n",
    "In the oprimization process, the objective one tries to minimize is \n",
    "\n",
    "$$\n",
    "f(\\mathbf{w}; X) = \\frac{1}{B \\times N} \\sum_{i=1}^{B \\times N} \\ell(\\mathbf{w}, \\mathbf{x}_i),\n",
    "$$\n",
    "\n",
    "where $f$ is a neural network, $B \\times N$ is the batch size, $\\ell$ is a loss function for each \n",
    "data point $\\mathbf{x} \\in X$, and $\\mathbf{w}$ is the trainable parameter of the\n",
    "neural newtwork. \n",
    "\n",
    "When taking the derivative of this objective, one gets,\n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} f(\\mathbf{w}; X) = \\frac{1}{B \\times N} \\sum_{i=1}^{B \\times N} \\nabla_{\\mathbf{w}} \\ell (\\mathbf{w}, \\mathbf{x}_i).\n",
    "$$\n",
    "\n",
    "Since the derivative has linearity, one can change the \n",
    "objective to the sum of summations each of which is the sum of derivatives over $B$ data points.    \n",
    "\n",
    "$$\n",
    "\\nabla_{\\mathbf{w}} f(\\mathbf{w}; X) = \\frac{1}{N} \\left(\n",
    " \\frac{1}{B} \\sum_{i=1}^{B} \\nabla_{\\mathbf{w}} \\ell (\\mathbf{w}, \\mathbf{x}_i) \\\n",
    " + \\frac{1}{B} \\sum_{i=B+1}^{B \\times 2} \\nabla_{\\mathbf{w}} \\ell (\\mathbf{w}, \\mathbf{x}_i) \\\n",
    " + \\ldots \\\n",
    " + \\frac{1}{B} \\sum_{i=B \\times (N-1) + 1}^{B \\times N} \\nabla_{\\mathbf{w}} \\ell (\\mathbf{w}, \\mathbf{x}_i)\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "In data parallel distributed training, the follwoing steps are peformed\n",
    "according to the above equation, \n",
    "\n",
    "1. each term, summation of derivatives (gradients) divided by batch size $B$, is computed on a separated device (tipically GPU),\n",
    "2. take the sum over devices,\n",
    "3. divide the result by the number of devices, $N$.\n",
    "\n",
    "That is the underlying foundation of Data Parallel Distributed Training.\n",
    "\n",
    "This tutorial shows the usage of Multi Process Data Parallel \n",
    "Communicator for data parallel distributed training with \n",
    "a very simple example.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE\n",
    "\n",
    "This tutorial depends on **IPython Cluster**, thus when you want to run the following excerpts of the scripts on Jupyter Notebook, follow **[this](https://ipython.org/ipython-doc/3/parallel/parallel_process.html#using-ipcluster-in-mpiexec-mpirun-mode)** to enable  mpiexec/mpirun mode, then launch a corresponding Ipython Cluster on Ipython Clusters tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Launch client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This codes are **only** needed for this turoial on **Jupyter Notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "rc = ipp.Client(profile='mpi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "import os\n",
    "import time\n",
    "\n",
    "import nnabla as nn\n",
    "import nnabla.communicators as C\n",
    "from nnabla.contrib.context import extension_context\n",
    "import nnabla.functions as F\n",
    "from nnabla.initializer import (\n",
    "    calc_uniform_lim_glorot,\n",
    "    UniformInitializer)\n",
    "import nnabla.parametric_functions as PF\n",
    "import nnabla.solvers as S\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the communicator for gradients exchange. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "extension_module = \"cuda.cudnn\"\n",
    "ctx = extension_context(extension_module)\n",
    "comm = C.mpDataParalellCommunicator(ctx)\n",
    "comm.init()\n",
    "n_devices = comm.size\n",
    "mpi_rank = comm.rank\n",
    "device_id = mpi_rank\n",
    "ctx = extension_context(extension_module, device_id=device_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check different ranks are assigned to different devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "n_devices=2\n",
      "mpi_rank=0\n",
      "[stdout:1] \n",
      "n_devices=2\n",
      "mpi_rank=1\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "print(\"n_devices={}\".format(n_devices))\n",
    "print(\"mpi_rank={}\".format(mpi_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data points and a very simple neural network  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "# Data points setting\n",
    "n_class = 2\n",
    "b, c, h, w = 4, 1, 32, 32 \n",
    "\n",
    "# Data points\n",
    "x_data = np.random.rand(b, c, h, w)\n",
    "y_data = np.random.choice(n_class, b).reshape((b, 1))\n",
    "x = nn.Variable(x_data.shape)\n",
    "y = nn.Variable(y_data.shape)\n",
    "x.d = x_data\n",
    "y.d = y_data\n",
    "\n",
    "# Network setting\n",
    "C = 1\n",
    "kernel = (3, 3)\n",
    "pad = (1, 1)\n",
    "stride = (1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "rng = np.random.RandomState(0)\n",
    "w_init = UniformInitializer(\n",
    "                    calc_uniform_lim_glorot(C, C/2, kernel=(1, 1)), \n",
    "                    rng=rng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "# Network\n",
    "with nn.context_scope(ctx):\n",
    "    h = PF.convolution(x, C, kernel, pad, stride, w_init=w_init)\n",
    "    pred = PF.affine(h, n_class, w_init=w_init)\n",
    "    loss = F.mean(F.softmax_cross_entropy(pred, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important notice** here is that `w_init` is passed to parametric functions\n",
    "to let the network on each GPU start from the same values of trainable parameters in the \n",
    "optimization process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add trainable parameters and create a solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "# Add parameters to communicator\n",
    "comm.add_context_and_parameters((ctx, nn.get_parameters()))\n",
    "\n",
    "# Solver and add parameters\n",
    "solver = S.Adam()\n",
    "solver.set_parameters(nn.get_parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the basic usage of `nnabla` API for training a neural netwrok,\n",
    "it is\n",
    "\n",
    "1. loss.forward()\n",
    "2. solver.zero_grad()\n",
    "3. loss.backward()\n",
    "4. solver.update()\n",
    "\n",
    "In use of `C.mpDataParalellCommunicator`, these steps are performed in \n",
    "different GPUs, and the **only difference** from these steps is `comm.allreduce()`\n",
    "Thus, in case of `C.mpDataParalellCommunicator` training steps are \n",
    "as follows, \n",
    "  \n",
    "1. loss.forward()\n",
    "2. solver.zero_grad()\n",
    "3. loss.backward()\n",
    "4. **comm.allreduce()**\n",
    "5. solver.update()\n",
    "\n",
    "First, forward, zero_grad, and backward,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "# Training steps\n",
    "loss.forward()\n",
    "solver.zero_grad()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check gradients of weights once, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "('conv/W', array([[[[ 0.06888472,  0.03302665,  0.00224538],\n",
      "         [ 0.10095084,  0.36394489,  0.00659006],\n",
      "         [ 0.15155329,  0.36173904,  0.20400617]]]], dtype=float32))\n",
      "('conv/b', array([ 0.09519047], dtype=float32))\n",
      "('affine/W', array([[ 0.23829283, -0.23829281],\n",
      "       [ 0.25489166, -0.25489166],\n",
      "       [ 0.07387832, -0.0738783 ],\n",
      "       ..., \n",
      "       [ 0.34147066, -0.34147066],\n",
      "       [ 0.33993909, -0.33993909],\n",
      "       [ 0.07020829, -0.07020829]], dtype=float32))\n",
      "('affine/b', array([ 0.18422271, -0.1842227 ], dtype=float32))\n",
      "[stdout:1] \n",
      "('conv/W', array([[[[ 0.28718406,  0.19707698,  0.21287963],\n",
      "         [ 0.27262157,  0.48162708,  0.58341372],\n",
      "         [ 0.09545794,  0.37022409,  0.39285854]]]], dtype=float32))\n",
      "('conv/b', array([ 0.45548177], dtype=float32))\n",
      "('affine/W', array([[ 0.19560671, -0.19560665],\n",
      "       [ 0.5929324 , -0.59293228],\n",
      "       [ 0.81732005, -0.81731993],\n",
      "       ..., \n",
      "       [ 0.30037487, -0.30037481],\n",
      "       [ 0.33988202, -0.33988199],\n",
      "       [ 0.1787488 , -0.1787488 ]], dtype=float32))\n",
      "('affine/b', array([ 0.23541948, -0.23541945], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "for n, v in nn.get_parameters().items():\n",
    "    print(n, v.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can see the different values on each device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "comm.allreduce(division=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly, `allreduce` only means the sum; however, `comm.allreduce` addresses\n",
    "both cases: summation and summation division. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check gradients of weights again,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "('conv/W', array([[[[ 0.17803439,  0.11505181,  0.1075625 ],\n",
      "         [ 0.1867862 ,  0.422786  ,  0.29500189],\n",
      "         [ 0.12350561,  0.36598158,  0.29843235]]]], dtype=float32))\n",
      "('conv/b', array([ 0.27533612], dtype=float32))\n",
      "('affine/W', array([[ 0.21694976, -0.21694973],\n",
      "       [ 0.42391205, -0.42391199],\n",
      "       [ 0.4455992 , -0.44559911],\n",
      "       ..., \n",
      "       [ 0.32092276, -0.32092273],\n",
      "       [ 0.33991057, -0.33991054],\n",
      "       [ 0.12447855, -0.12447855]], dtype=float32))\n",
      "('affine/b', array([ 0.20982111, -0.20982108], dtype=float32))\n",
      "[stdout:1] \n",
      "('conv/W', array([[[[ 0.17803439,  0.11505181,  0.1075625 ],\n",
      "         [ 0.1867862 ,  0.422786  ,  0.29500189],\n",
      "         [ 0.12350561,  0.36598158,  0.29843235]]]], dtype=float32))\n",
      "('conv/b', array([ 0.27533612], dtype=float32))\n",
      "('affine/W', array([[ 0.21694976, -0.21694973],\n",
      "       [ 0.42391205, -0.42391199],\n",
      "       [ 0.4455992 , -0.44559911],\n",
      "       ..., \n",
      "       [ 0.32092276, -0.32092273],\n",
      "       [ 0.33991057, -0.33991054],\n",
      "       [ 0.12447855, -0.12447855]], dtype=float32))\n",
      "('affine/b', array([ 0.20982111, -0.20982108], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "for n, v in nn.get_parameters().items():\n",
    "    print(n, v.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the same values over the devices because of `allreuce`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update weights,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "solver.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all for the usage of `C.mpDataParallelCommunicator` in the sense \n",
    "of Data Parallel Distributed Training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you got the picture of using `C.mpDataParallelCommunicator`, go to the cifar10 example,\n",
    "\n",
    "1. **multi_device_multi_process_classification.sh**\n",
    "2. **multi_device_multi_process_classification.py**  \n",
    "\n",
    "for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

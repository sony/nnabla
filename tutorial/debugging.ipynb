{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep neural networks are going deeper and deeper every year, requiring more components in the networks. Such complexity often misleads us to mal-configure the networks that can turn out be critical. Even if we correctly configure a neural network as desired, we may still want to find out its performance bottleneck, e.g., from which layer(s) the computational bottleneck comes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this debugging tutorial, we introduce the following ways to deal with such cases:\n",
    "\n",
    "1. `visit` method of a variable\n",
    "2. pretty-print\n",
    "3. simple graph viewer\n",
    "4. profiling utils\n",
    "5. value tracer\n",
    "\n",
    "We will go over each technique, but first prepare the following reference model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nnabla-ext-cuda100\n",
    "!git clone https://github.com/sony/nnabla.git\n",
    "%cd nnabla/tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nnabla as nn\n",
    "import nnabla.logger as logger\n",
    "import nnabla.functions as F\n",
    "import nnabla.parametric_functions as PF\n",
    "import nnabla.solvers as S\n",
    "\n",
    "def block(x, maps, test=False, name=\"block\"):\n",
    "    h = x\n",
    "    with nn.parameter_scope(name):\n",
    "        with nn.parameter_scope(\"in-block-1\"):\n",
    "            h = PF.convolution(h, maps, kernel=(3, 3), pad=(1, 1), with_bias=False)\n",
    "            h = PF.batch_normalization(h, batch_stat=not test)\n",
    "            h = F.relu(h)\n",
    "        with nn.parameter_scope(\"in-block-2\"):\n",
    "            h = PF.convolution(h, maps // 2, kernel=(3, 3), pad=(1, 1), with_bias=False)\n",
    "            h = PF.batch_normalization(h, batch_stat=not test)\n",
    "            h = F.relu(h)\n",
    "        with nn.parameter_scope(\"in-block-3\"):\n",
    "            h = PF.convolution(h, maps, kernel=(3, 3), pad=(1, 1), with_bias=False)\n",
    "            h = PF.batch_normalization(h, batch_stat=not test)\n",
    "            \n",
    "        if h.shape[1] != x.shape[1]:\n",
    "            with nn.parameter_scope(\"skip\"):\n",
    "                s = PF.convolution(x, maps, kernel=(3, 3), pad=(1, 1), with_bias=False)\n",
    "                s = PF.batch_normalization(s, batch_stat=not test)\n",
    "\n",
    "    return F.relu(h + s)\n",
    "\n",
    "def network(x, maps=16, test=False):\n",
    "    h = x\n",
    "    h = PF.convolution(h, maps, kernel=(3, 3), pad=(1, 1), name=\"first-conv\", with_bias=False)\n",
    "    h = PF.batch_normalization(h, batch_stat=not test, name=\"first-bn\")\n",
    "    h = F.relu(h)\n",
    "    for l in range(4):\n",
    "        h = block(h, maps * 2 ** (l + 1), name=\"block-{}\".format(l))\n",
    "        h = F.max_pooling(h, (2, 2))\n",
    "    h = F.average_pooling(h, h.shape[2:])\n",
    "    pred = PF.affine(h, 100, name=\"pred\")\n",
    "    return pred      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visit Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit method of a variable takes either lambda, function, callable object as an argument and calls it over all NNabla functions where the variable can traverse in the forward order. It is easier to see the usage than expalined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, define the callable class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintFunc(object):\n",
    "    def __call__(self, nnabla_func):\n",
    "        print(\"==========\")\n",
    "        print(nnabla_func.info.type_name)\n",
    "        print(nnabla_func.inputs)\n",
    "        print(nnabla_func.outputs)\n",
    "        print(nnabla_func.info.args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This callable object takes a NNabla function, e.g., convolution, relu, etc., so a user can get information of that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()  # this call is just in case to do the following code again\n",
    "\n",
    "x = nn.Variable.from_numpy_array(np.random.randn(*[4, 3, 128, 128]))\n",
    "pred = network(x)\n",
    "pred.visit(PrintFunc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the low-level API to see the graph information as you want by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPrint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PPrint method is one of the instantiation of the visit method. We can see the graph structure in the topological (forward) order in details. Here is a usage to see detailed information of a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()  # call this in case you want to run the following code agian\n",
    "\n",
    "x = nn.Variable.from_numpy_array(np.random.randn(*[4, 3, 128, 128]))\n",
    "pred = network(x)\n",
    "\n",
    "# pprint\n",
    "from nnabla.utils.inspection import pprint\n",
    "pprint(pred, summary=True, forward=True, backward=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Graph Viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visit method is very useful for getting information about each function\n",
    "used in a graph, but it is hard to see the details of the whole network\n",
    "structure, e.g., which variable is connected to which variable. So we have a graph viewer that visually shows the whole structure of network, enabling us to debug more efficiently. Using this graph viewer is straightforward, as shown in the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()  # call this in case you want to run the following code agian\n",
    "\n",
    "x = nn.Variable([4, 3, 128, 128])\n",
    "pred = network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nnabla.experimental.viewers as V\n",
    "\n",
    "graph = V.SimpleGraph(verbose=False)\n",
    "graph.view(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one would like to see more detailed information as in `visit` method case, change verbose option to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = V.SimpleGraph(verbose=True)\n",
    "graph.view(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now one can see detailed information!\n",
    "\n",
    "Note that this viewer is mainly for NNabla users who want to write codes in python, so for those who like to see more beautiful network and play with that, please use Neural Network Console and visit https://dl.sony.com/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, this feature is **for developers** who want to know the whole stats in speed and which functions could be bottlenecks. NNabla provides a simple profiling tool. Once a network is prepared, one better to have other components to train the network like a loss function and solvers.\n",
    "\n",
    "To create the profiler and see the results, run the following codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.clear_parameters()  # call this in case you want to run the following code agian\n",
    "\n",
    "# Context\n",
    "from nnabla.ext_utils import get_extension_context\n",
    "device = \"cudnn\"\n",
    "ctx = get_extension_context(device)\n",
    "nn.set_default_context(ctx)\n",
    "\n",
    "# Network\n",
    "x = nn.Variable.from_numpy_array(np.random.randn(*[4, 3, 128, 128]))\n",
    "t = nn.Variable([4, 1])\n",
    "pred = network(x)\n",
    "loss = F.mean(F.softmax_cross_entropy(pred, t))\n",
    "\n",
    "# Solver\n",
    "solver = S.Momentum()\n",
    "solver.set_parameters(nn.get_parameters())\n",
    "\n",
    "# Profiler\n",
    "from nnabla.utils.profiler import GraphProfiler\n",
    "B = GraphProfiler(loss, solver=solver, device_id=0, ext_name=device, n_run=100)\n",
    "B.run()\n",
    "print(\"Profile finished.\")\n",
    "\n",
    "# Report\n",
    "from nnabla.utils.profiler import GraphProfilerCsvWriter\n",
    "with open(\"./profile.csv\", \"w\") as f:\n",
    "    writer = GraphProfilerCsvWriter(B, file=f)\n",
    "    writer.write()\n",
    "print(\"Report is prepared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find [TimeProfiler](http://43.196.179.83:8000/build-doc/doc/html/python/api/utils/debug_utils.html#nnabla.utils.inspection.profile.TimeProfiler) to profile, but it is more fine-grained in measureing execution time.\n",
    "\n",
    "With TimeProfiler, you can put a callback function to the forward and/or backward method in the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Tracer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sometimes want to check if there exsits NaN/Inf. NanInfTracer is a convenient way to check if one of all layers in a graph has NaN/Inf value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create graph again just in case\n",
    "nn.clear_parameters()  # call this in case you want to run the following code agian\n",
    "\n",
    "# Try to switch these two\n",
    "x = nn.Variable.from_numpy_array(np.random.randn(*[4, 3, 64, 64]))\n",
    "#x = nn.Variable([4, 3, 64, 64])\n",
    "pred = network(x)\n",
    "\n",
    "# NanInfTracer\n",
    "from nnabla.utils.inspection import NanInfTracer\n",
    "nit = NanInfTracer(trace_inf=True, trace_nan=True, need_details=True)\n",
    "\n",
    "with nit.trace():\n",
    "    # Try to comment either of these two or both\n",
    "    pred.forward(function_post_hook=nit.forward_post_hook)\n",
    "    pred.backward(function_post_hook=nit.backward_post_hook)\n",
    "    \n",
    "print(nit.check())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "accelerator": "GPU", 
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
